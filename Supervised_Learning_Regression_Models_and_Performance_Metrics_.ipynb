{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Supervised Learning: Regression Models and Performance Metrics"
      ],
      "metadata": {
        "id": "Nelm7RdP4zgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.1 What is Simple Linear Regression (SLR)? Explain its purpose."
      ],
      "metadata": {
        "id": "YI3Q42l845NF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> Simple Linear Regression (SLR) is a statistical method used to study the relationship between two continuous variables ‚Äî one independent variable (X) and one dependent variable (Y).\n",
        "\n",
        "Simple Linear Regression finds the best-fitting straight line (called the regression line) through a set of data points, which can be represented by the equation:\n",
        "\n",
        "Y=b0‚Äã+b1‚ÄãX+Œµ\n",
        "\n",
        "Where:\n",
        "\n",
        "Y = Dependent variable\n",
        "\n",
        "X = Independent variable\n",
        "\n",
        "ùëè\n",
        "0 = Intercept (value of\n",
        "Y when\n",
        "X=0)\n",
        "\n",
        "b1= Slope\n",
        "  (how much\n",
        "Y changes for each unit change in\n",
        "X)\n",
        "\n",
        "Œµ = Error term (difference between actual and predicted values)\n",
        "\n",
        "Purpose of Simple Linear Regression\n",
        "\n",
        "- Prediction:\n",
        "To predict the value of the dependent variable based on a known value of the independent variable.\n",
        "Example: Predicting house price (Y) based on its size (X).\n",
        "\n",
        "- Understanding relationships:\n",
        "To quantify the strength and direction of the relationship between two variables.\n",
        "\n",
        "    - Positive slope -> as X increases, Y increases.\n",
        "\n",
        "    - Negative slope -> as X increases, Y decreases.\n",
        "\n",
        "- Trend estimation: To identify and model trends in data, often used in forecasting.\n",
        "\n",
        "Example\n",
        "\n",
        "Suppose you want to predict a student's exam score (Y) based on study hours (X):\n",
        "\n",
        "Hours Studied (X) : 2, 4, 6, 8\n",
        "\n",
        "Exam Score (Y) : 50, 65, 80, 90\n",
        "\n",
        "The regression model might find an equation:\n",
        "\n",
        "Y=40+6X\n",
        "\n",
        "That means for every additional hour studied, the score increases by 6 points."
      ],
      "metadata": {
        "id": "kvIdutaM5HYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.2 What are the key assumptions of Simple Linear Regression?"
      ],
      "metadata": {
        "id": "--5_fqIv5Gz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> The key assumptions of Simple Linear Regression (SLR) ensure that the model estimates are reliable, unbiased, and statistically valid.\n",
        "\n",
        "Here are the five main assumption\n",
        "\n",
        "1.Linearity\n",
        "\n",
        "The relationship between the independent variable (X) and the dependent variable (Y) is linear.\n",
        "\n",
        "This means that a change in X results in a proportional change in Y.\n",
        "\n",
        "Example: If hours studied increases, marks should increase at a roughly constant rate.\n",
        "\n",
        "2.Independence of Errors\n",
        "\n",
        "The residuals (errors) ‚Äî the differences between actual and predicted Y ‚Äî should be independent of each other.\n",
        "\n",
        "This means there is no correlation among error terms.\n",
        "\n",
        "Example: One student's exam performance should not influence another's.\n",
        "\n",
        "3.Homoscedasticity (Constant Variance of Errors)\n",
        "\n",
        "The variance of the residuals should be constant across all values of X.\n",
        "\n",
        "If the spread of residuals increases or decreases with X, it indicates heteroscedasticity.\n",
        "\n",
        "Example: Prediction errors should be equally spread for both low and high study hours.\n",
        "\n",
        "4.Normality of Errors\n",
        "\n",
        "The residuals should be normally distributed (bell-shaped).\n",
        "\n",
        "This is important for making valid statistical tests (like t-tests for coefficients).\n",
        "\n",
        "5.No Perfect Multicollinearity\n",
        "\n",
        "In Simple Linear Regression, there only one predictor, so this assumption is automatically satisfied.\n",
        "\n",
        "(It becomes important in Multiple Linear Regression, where predictors should not be highly correlated.)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lauQ53qU9Nb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3 Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.\n"
      ],
      "metadata": {
        "id": "3fnkC-UT_Mwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> The mathematical equation for a Simple Linear Regression (SLR) model\n",
        "\n",
        "ùëå =\n",
        "ùëè\n",
        "0\n",
        "+\n",
        "ùëè\n",
        "1\n",
        "ùëã\n",
        "+\n",
        "ùúÄ\n",
        "\n",
        "Explanation of Each Term\n",
        "\n",
        "Y (Dependent Variable) : The variable we are trying to predict or explain (e.g.- house price, marks, sales).\n",
        "\n",
        "X (Independent Variable) : The variable used to make predictions (e.g.- area of house, study hours, advertisement spend).\n",
        "\n",
        "b0 (Intercept) : The expected value of Y when X=0. It represents the point where the regression line crosses the Y-axis.\n",
        "\n",
        "b1 (Slope Coefficient) : The average change in Y for each one-unit increase in X. It shows the strength and direction of the relationship between X and Y.\n",
        "\n",
        "Œµ (Error Term) : The difference between the actual value of Y and the predicted value from the model. It accounts for factors not explained by X.\n",
        "\n",
        "Example\n",
        "\n",
        "Suppose you are predicting a student's exam score (Y) based on the number of hours studied (X).\n",
        "\n",
        "The regression equation might be:\n",
        "\n",
        "Y = 40 + 6X + Œµ\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "b0 ‚Äã= 40 : A student who studies 0 hours is expected to score 40 marks.\n",
        "\n",
        "b1 ‚Äã= 6 : For each additional hour studied, the exam score increases by 6 marks (on average)\n",
        "\n",
        "Œµ: Random error - captures variation in scores not explained by study hours.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VHaYi4vA_YhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.4 Provide a real-world example where simple linear regression can be\n",
        "applied."
      ],
      "metadata": {
        "id": "6DLLwBDeCrtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> Real-world example of where Simple Linear Regression (SLR) can be applied\n",
        "\n",
        "Predicting House Prices Based on Size\n",
        "\n",
        "Scenario:\n",
        "\n",
        "A real estate company wants to predict the price of a house based on its size (in square feet).\n",
        "\n",
        "They collect data on several houses:\n",
        "\n",
        "House Size (sq. ft.) : 800, 1000, 1200, 1500, 1800\n",
        "\n",
        "Price (‚Çπ Lakhs) : 45, 55, 65, 80, 95\n",
        "\n",
        "Applying Simple Linear Regression:\n",
        "\n",
        "We assume a linear relationship between house size (X) and price (Y):\n",
        "\n",
        "Y=b0‚Äã+b1‚ÄãX+Œµ\n",
        "\n",
        "After fitting the model, we might get:\n",
        "\n",
        "Predicted Price=20+0.04X\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "b0=20: The base price (even for a house of size 0) is ‚Çπ20 lakhs.\n",
        "\n",
        "b1=0.04: For every additional 1 sq. ft. of area, the house price increases by ‚Çπ0.04 lakhs (i.e., ‚Çπ4,000).\n",
        "\n",
        "So, for a 1,500 sq. ft. house:\n",
        "\n",
        "Price=20+0.04(1500)=80 lakhs (approx.)\n",
        "\n",
        "Purpose of Using SLR Here\n",
        "\n",
        "- Prediction: Estimate house prices for new listings.\n",
        "\n",
        "- Understanding: Quantify how much house size affects price.\n",
        "\n",
        "- Decision-making: Help buyers and sellers determine fair market values\n",
        "\n"
      ],
      "metadata": {
        "id": "J02HjxuYC4Kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5 What is the method of least squares in linear regression?"
      ],
      "metadata": {
        "id": "2MStxKEAEu3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> The method of least squares is the most common technique used to find the best-fitting line in a linear regression model.\n",
        "\n",
        "It works by minimizing the sum of the squared differences (errors) between the observed values and the predicted values given by the regression line.\n",
        "\n",
        "Mathematical Explanation\n",
        "\n",
        "The simple linear regression model is:\n",
        "\n",
        "Y=b0‚Äã+b1‚ÄãX+Œµ\n",
        "\n",
        "We have:\n",
        "\n",
        "Yi : Actual observed value\n",
        "\n",
        "ùëåi = ùëè0 + ùëè1ùëãi : Predicted value from the regression line\n",
        "\n",
        "ei = Yi - Yi : Residual\n",
        "\n",
        "Goal of Least Squares\n",
        "\n",
        "The goal is to minimize the sum of squared residuals (errors):\n",
        "\n",
        "Minimize¬†S=i=1‚àën‚Äã(Yi‚Äã‚àíYi‚Äã^‚Äã)2=i=1‚àën‚Äã(Yi‚Äã‚àíb0‚Äã‚àíb1‚ÄãXi‚Äã)2\n",
        "\n",
        "Formulas for the Coefficients\n",
        "\n",
        "By minimizing S with respect to b0 and b1, we get:\n",
        "\n",
        "b1 = ‚àë(Xi‚Äã‚àíXÀâ)(Yi‚Äã‚àíYÀâ)‚Äã / ‚àë(Xi‚Äã‚àíXÀâ)^2\n",
        "\n",
        "b0 = YÀâ‚àíb1‚ÄãXÀâ\n",
        "\n",
        "Where:\n",
        "\n",
        "XÀâ = Mean of X values\n",
        "\n",
        "YÀâ = Mean of Y values\n",
        "\n",
        "These formulas give the slope and intercept of the line of best fit.\n",
        "\n",
        "Interpretation\n",
        "\n",
        "The slope (b1) shows how much Y changes for a one-unit change in X.\n",
        "\n",
        "The intercept (b0) shows the predicted value of Y when X=0.\n",
        "\n",
        "The method of least squares finds the best-fitting regression line by minimizing the sum of squared errors between the actual and predicted values ‚Äî ensuring the most accurate and unbiased linear fit for the data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "71_zE2CcE4lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.6 What is Logistic Regression? How does it differ from Linear Regression?\n"
      ],
      "metadata": {
        "id": "uOssiC1HJkIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> Logistic Regression ‚Äì Overview\n",
        "\n",
        "Logistic Regression is a statistical method used for classification problems, where the dependent variable (Y) is categorical, usually binary (e.g., Yes/No, 0/1, Pass/Fail).\n",
        "\n",
        "It predicts the probability that an observation belongs to a particular category.\n",
        "\n",
        "Purpose\n",
        "\n",
        "To model the probability that Y=1 (the ‚Äúsuccess‚Äù class) given an independent variable X.\n",
        "\n",
        "Mathematical Form\n",
        "\n",
        "Instead of fitting a straight line (like in linear regression), Logistic Regression fits an S-shaped curve (sigmoid function):\n",
        "\n",
        "P(Y=1‚à£X)=1 / 1+e‚àí(b0‚Äã+b1‚ÄãX)1‚Äã\n",
        "\n",
        "Where:\n",
        "\n",
        "P(Y=1‚à£X) = Probability that the outcome is 1\n",
        "\n",
        "b0 = Intercept\n",
        "\n",
        "b1= Coefficient of X\n",
        "\n",
        "e = Base of the natural logarithm (~2.718)\n",
        "\n",
        "The output is always between 0 and 1, making it ideal for probability estimation.\n",
        "\n",
        "Decision Rule\n",
        "\n",
        "If:\n",
        "P(Y=1‚à£X)‚â•0.5 - Predict 1 (Yes / Success)\n",
        "\n",
        "P(Y=1‚à£X)<0.5 - Predict 0 (No / Failure)\n",
        "\n",
        "Difference Between Linear Regression and Logistic Regression\n",
        "\n",
        "Linear Regression\n",
        "\n",
        " - Predicts a continuous outcome\n",
        " - Output can be any real number (‚àí‚àû to +‚àû).\n",
        " - Y = b0 + b1X + Œµ\n",
        " - Models a linear relationship between X and Y.\n",
        " - Predicting sales, income, temperature, etc.\n",
        " - Uses Mean Squared Error (MSE).\n",
        "\n",
        "\n",
        "Logistic Regression\n",
        "\n",
        " - Predicts a categorical outcome (e.g., yes/no, pass/fail).\n",
        " - Output is a probability between 0 and 1.\n",
        " - P(Y=1‚à£X)=1 / 1+e‚àí(b0‚Äã+b1‚ÄãX)1‚Äã\n",
        " - Models a non-linear relationship between X and the probability of Y.\n",
        " - Predicting churn, disease presence, email spam, etc.\n",
        " - Uses Log-Loss / Cross-Entropy.\n",
        "\n",
        "\n",
        " Linear Regression predicts continuous values, while Logistic Regression predicts probabilities for categorical outcomes using the sigmoid function to keep predictions between 0 and 1."
      ],
      "metadata": {
        "id": "Udn7jS1LJxuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.7 Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n"
      ],
      "metadata": {
        "id": "_XmvsjGCSK3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> Three common evaluation metrics for regression models, along with brief descriptions:\n",
        "\n",
        "1.Mean Absolute Error (MAE)\n",
        "\n",
        "MAE measures the average absolute difference between the actual values and the predicted values.\n",
        "\n",
        "MAE=ni=1‚àën‚Äã‚à£yi‚Äã‚àíy^‚Äãi‚Äã‚à£\n",
        "\n",
        " - It shows how far predictions are from actual values on average.\n",
        "\n",
        " - Smaller MAE ‚Üí better model performance.\n",
        "\n",
        " - It's easy to interpret since it uses the same unit as the target variable.\n",
        "\n",
        "2.Mean Squared Error (MSE)\n",
        "\n",
        "MSE calculates the average of squared differences between actual and predicted values.\n",
        "\n",
        "MSE=n‚Äãi=1‚àën‚Äã(yi‚Äã‚àíy^‚Äãi‚Äã)2\n",
        "\n",
        " - Penalizes larger errors more heavily.\n",
        "\n",
        " - Smaller MSE indicates better performance.\n",
        "\n",
        " - Useful when large errors are especially undesirable.\n",
        "\n",
        "3.R-squared\n",
        "\n",
        "R¬≤ measures the proportion of variance in the dependent variable that is predictable from the independent variable(s).\n",
        "\n",
        "R2=1‚àí SSres‚Äã‚Äã/SStot\n",
        "\n",
        " - R¬≤ ranges from 0 to 1.\n",
        "\n",
        " - Higher R¬≤ - better fit (closer to 1 means predictions explain most of the variance).\n",
        "\n"
      ],
      "metadata": {
        "id": "kLzx3t1Wwvcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.8 What is the purpose of the R-squared metric in regression analysis?\n"
      ],
      "metadata": {
        "id": "tAxCH7_iytit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> The purpose of the R-squared (R¬≤) metric in regression analysis is to measure how well the regression model explains the variability of the dependent (target) variable based on the independent (predictor) variables.\n",
        "\n",
        "R¬≤ tells you how much of the total variation in the actual data is captured or explained by your model.\n",
        "\n",
        "SSres = ‚àë(yi - y^i)2 - Residual sum of squares (unexplained variation)\n",
        "\n",
        "SStot‚Äã=‚àë(yi‚Äã‚àíyÀâ‚Äã)2 - Total sum of squares (total variation)\n",
        "\n",
        "Interpretation:\n",
        "\n",
        " - R¬≤ = 1: Perfect fit ‚Äî model explains all the variation in the data.\n",
        "\n",
        " - R¬≤ = 0: Model explains none of the variation (as good as using the mean).\n",
        "\n",
        " - Higher R¬≤ ‚Üí Better model fit, meaning predictions are closer to actual values.\n",
        "\n",
        "If R¬≤ = 0.85, it means 85% of the variation in the dependent variable can be explained by the model, while 15% is due to other factors or random noise.\n",
        "\n"
      ],
      "metadata": {
        "id": "nPSE8zDKy8Gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.9 Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.\n"
      ],
      "metadata": {
        "id": "RPpHGQG77d_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# data (X = independent variable, y = dependent variable)\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # X must be 2D\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Create and fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print slope (coefficient) and intercept\n",
        "print(\"Slope (Coefficient):\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZkPbakP7yPZ",
        "outputId": "c6c7a7c2-3df6-4c22-ba41-6dbc8b23e7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 0.6\n",
            "Intercept: 2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.10 How do you interpret the coefficients in a simple linear regression model?"
      ],
      "metadata": {
        "id": "dEu3onjD87pW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> In a Simple Linear Regression model, the relationship between the independent variable X and the dependent variable Y is expressed as:\n",
        "\n",
        "Y=Œ≤0‚Äã+Œ≤1‚ÄãX+Œµ\n",
        "\n",
        "Where:\n",
        "\n",
        "Œ≤0= Intercept\n",
        "\n",
        "Œ≤1= Slope (Coefficient)\n",
        "\n",
        "Œµ = Error term\n",
        "\n",
        "Interpretation of Coefficients:\n",
        "\n",
        "1.Intercept (Œ≤0)\n",
        "\n",
        "It represents the predicted value of Y when X = 0.\n",
        "\n",
        "In other words, it's the point where the regression line crosses the Y-axis.\n",
        "\n",
        "Example: If\n",
        "\n",
        "Œ≤0=5, when\n",
        "X=0, the model predicts\n",
        "Y=5\n",
        "\n",
        "2.Slope (Œ≤1)\n",
        "\n",
        "It represents the change in Y for a one-unit increase in X.\n",
        "\n",
        "In other words, it tells how much\n",
        "\n",
        "Y increases (or decreases) when\n",
        "\n",
        "X increases by 1 unit.\n",
        "\n",
        "Example: If\n",
        "Œ≤1=2.5, then for every 1-unit increase in\n",
        "\n",
        "X, Y increases by 2.5 units, on average.\n",
        "\n",
        "Example Interpretation:\n",
        "\n",
        "If your regression equation is:\n",
        "\n",
        "Y^=3+1.2\n",
        "\n",
        "Then:\n",
        "\n",
        "Intercept (3): When X=0, predicted\n",
        "Y=3.\n",
        "\n",
        "Slope (1.2): For every increase of 1 unit in\n",
        "X, Y increases by 1.2 units.\n"
      ],
      "metadata": {
        "id": "Z5yMK4km9N4v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lk0HhbAd8-GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QA6LIE_g8lLZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}